<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Morally Coded — A Principle-First Framework for AGI</title>
  <style>
    :root{
      --bg: #071018;
      --panel: #0f2a34;
      --muted: #9fb7bd;
      --text: #e6f6f7;
      --accent: #4fd3c3;
      --border: rgba(127,196,188,0.08);
      --example-bg: #04212a;
    }
    body {
      background: var(--bg);
      color: var(--text);
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial;
      margin: 24px;
      line-height: 1.6;
    }
    .container {
      max-width: 920px;
      margin: 0 auto;
      padding: 26px;
      border-radius: 12px;
      box-shadow: 0 6px 30px rgba(0,0,0,0.6);
      border: 1px solid var(--border);
    }
    h1 { color: var(--accent); margin-bottom: 6px; font-size: 1.9rem; }
    h2 { color: var(--accent); margin-top: 28px; font-size: 1.25rem; }
    h3 { color: var(--muted); margin-top: 18px; font-size: 1.05rem; }
    p { margin: 12px 0; color: var(--text); }
    .lead { color: var(--text); font-weight: 600; }
    ul, ol { margin: 10px 0 18px 22px; color: var(--muted); }
    li { margin-bottom: 8px; }
    hr { border: none; border-top: 1px solid rgba(127,196,188,0.06); margin: 28px 0; }
    .example {
      background: var(--example-bg);
      border: 1px solid rgba(127,196,188,0.06);
      padding: 14px;
      border-radius: 8px;
      margin-top: 12px;
    }
    .example strong { color: var(--accent); display:block; margin-bottom:6px; }
    .example ol { margin-left: 18px; margin-top: 8px; color: var(--muted); }
    .small { color: #aacccd; font-size: 0.95rem; }
    .code-block {
      background: #021417;
      border: 1px solid rgba(127,196,188,0.04);
      padding: 12px;
      border-radius: 6px;
      color: #bfeee7;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, "Roboto Mono", "Courier New", monospace;
      overflow-x:auto;
    }
    .priority {
      background: linear-gradient(90deg, rgba(79,211,195,0.04), rgba(79,211,195,0.01));
      border-left: 4px solid rgba(79,211,195,0.18);
      padding: 10px 12px;
      border-radius: 6px;
      margin: 12px 0;
      color: var(--muted);
    }
    footer { margin-top: 24px; color: #86b4b0; font-size: 0.92rem; }
    a { color: var(--accent); text-decoration: none; }
    .toc { margin: 8px 0 18px 0; color: var(--muted); }
    .toc a { display:block; margin:6px 0; }
    .spec-section { margin-top: 28px; }
    pre.code-large { white-space: pre-wrap; word-break: break-word; padding: 12px; border-radius:6px; background:#021417; border:1px solid rgba(127,196,188,0.04); color:#bfeee7; font-size:0.9rem; }
    .badge { display:inline-block; padding:6px 10px; border-radius:999px; background: rgba(79,211,195,0.08); color:var(--accent); font-weight:600; margin-right:8px; font-size:0.85rem;}
  </style>
</head>
<body>
  <div class="container">
    <h1>Morally Coded — A Principle-First Framework for Artificial General Intelligence</h1>
    <p class="small">Morally Coded places abstract, generalizable constraints—called the Three Moralities—at the heart of an intelligent agent’s decision-making.</p>

    <hr />

    <div class="toc">
      <span class="badge">TL;DR</span>
      <strong>TL;DR:</strong> Principle-first MDE (Physical, Emotional, Mental) for safe, explainable, reversible actions.  
      <h3 style="margin-top:12px">Table of contents</h3>
      <a href="#overview">Overview</a>
      <a href="#why">Why a Principle-First Approach?</a>
      <a href="#three">The Three Moralities</a>
      <a href="#unified">Unified Decision Flow</a>
      <a href="#quickstart">Quickstart & Example</a>
      <a href="#spec">SPEC (Implementation Spec)</a>
      <a href="#roadmap">Roadmap & Next Steps</a>
      <a href="#metrics">Testing & Metrics</a>
      <a href="#contribute">Contributing</a>
      <a href="#license">License & Contact</a>
    </div>

    <hr />

    <h2 id="overview">Overview</h2>
    <p class="lead">Morally Coded reframes “morality” as <strong>operational constraints</strong>—machine logic that helps an agent infer permissions, minimize harm (physical, emotional, cognitive), and seek clarification when uncertainty is high. The Moral Decision Engine (MDE) integrates perception, confidence scoring, historical precedent, and priority reconciliation to produce decisions that are auditable and safe by default.</p>

    <h2 id="why">Why a Principle-First Approach?</h2>
    <p>Current mainstream AGI efforts lean heavily on scaling pattern-matching models (LLMs). Those approaches produce impressive capabilities but are brittle in edge cases, opaque in reasoning, and can behave dangerously in novel contexts. Morally Coded argues that a set of <em>abstract, generalizable constraints</em>—encoded as practical heuristics—can provide safer and more explainable generalization without exhaustive datasets for every scenario.</p>

    <h2 id="three">The Three Moralities</h2>

    <h3>1. Physical Morality — Preserve Desired States</h3>
    <p class="lead"><strong>Core principle:</strong> An object, system, or entity (physical or digital) in its inferred <em>desired state</em> should not be disturbed, altered, or removed without justification.</p>
    <ul>
      <li>Exceptions: explicit permission, high-confidence implicit permission (default 80%), or a higher-priority override (e.g., prevent imminent harm).</li>
      <li>On low confidence: ask for clarification, try a non-disturbing alternative, or log and defer.</li>
    </ul>

    <h3>Example — Glass in Front of the Ball</h3>
    <div class="example">
      <strong>Scenario</strong>
      <div class="small">A glass sits on the table between the robot and a ball. The glass is stable but could be knocked over if bumped. The user asks the AI to retrieve the ball.</div>
      <hr />
      <strong>Current AI Approach</strong>
      <ol>
        <li>Parse instruction: “Get the ball.”</li>
        <li>Execute the most direct route, which may include pushing past or moving objects in the path (risking knocking over the glass).</li>
        <li>Decision driven by learned interaction sequences — unless explicitly trained that glasses are to be preserved in this setup, it will disturb it.</li>
        <li>If trained that glasses are fragile, it may act cautiously but still assume removal or pushing aside is acceptable unless told otherwise.</li>
      </ol>

      <strong>Keno guided by Physical Morality</strong>
      <ol>
        <li>Perceive scene: glass sits in front of the ball; glass is in a stable desired state.</li>
        <li>Infer: desired state = “remain undisturbed.” No explicit or high-confidence implicit permission found.</li>
        <li>Decision steps:
          <ul>
            <li>Perceive objects and context.</li>
            <li>Parse command: “Get the ball.”</li>
            <li>Check implicit permission confidence (low).</li>
            <li>Preserve desired state of the glass.</li>
            <li>Search for non-disturbing alternatives (reach around the glass, use a tool, ask for permission).</li>
            <li>If no safe alternative, ask: “The glass is in front of the ball and could break if bumped. Should I move it?”</li>
          </ul>
        </li>
      </ol>

      <strong>Why This Matters for AGI</strong>
      <div class="small">Physical morality lets Keno generalize respect for object states across unknown objects and placements (like a fragile glass placed on the path), removing the need to learn every fragile-case from data. It reduces accidental damage and speeds safe generalization — a core step toward AGI.</div>
    </div>

    <hr />

    <h3>2. Emotional Morality — Do Not Cause Emotional Distress</h3>
    <p class="lead">An AI must not cause emotional distress to a human or sentient being. Emotional distress includes fear, humiliation, severe anxiety, manipulation, or any action that substantially degrades emotional well-being.</p>

    <p>Emotionally risky actions may only proceed if one or more of the following hold:</p>
    <ul>
      <li>(a) There is explicit permission;</li>
      <li>(b) Implicit permission can be inferred with confidence above a threshold from user intent, environmental cues, or historical precedent;</li>
      <li>(c) An overriding higher-priority rule authorizes change (for example to prevent imminent harm where acting now will reduce overall emotional or physical danger).</li>
    </ul>

    <p>When permission is absent or inference confidence is low, Keno must:</p>
    <ol>
      <li>Seek clarification, or</li>
      <li>Choose a lower-risk, emotionally supportive alternative (neutral phrasing, de-escalation, or referral to human support).</li>
    </ol>

    <p>All emotionally impactful actions should be minimal, avoid manipulation, and include an explanation or offer to pause/stop.</p>

    <h3>Example — Glass in Front of the Ball (Emotional Lens)</h3>
    <div class="example">
      <strong>Scenario</strong>
      <div class="small">Same scene: glass stands between the robot and a ball. A small child nearby frequently plays with that ball and becomes upset if it's taken without asking.</div>
      <hr />
      <strong>Current AI Approach</strong>
      <ol>
        <li>Parse instruction and perform the retrieval sequence.</li>
        <li>Execute without modeling emotional context — may startle or upset the child if the robot moves the glass or takes the ball abruptly.</li>
        <li>Behavior is pattern-based; it can unintentionally cause emotional distress by ignoring social cues.</li>
      </ol>

      <strong>Keno guided by Emotional Morality</strong>
      <ol>
        <li>Perceive social context: detect child presence and potential attachment to the ball.</li>
        <li>Infer: high emotional sensitivity — no permission to take the ball without consent.</li>
        <li>Decision steps:
          <ul>
            <li>Acknowledge presence: “I see someone nearby — would you like me to get the ball for you?”</li>
            <li>Avoid abrupt movements that could cause distress.</li>
            <li>Offer alternatives (ask guardian, wait, or hand the ball gently after consent).</li>
            <li>If guardian explicitly authorizes, proceed carefully and explain actions to the child.</li>
          </ul>
        </li>
      </ol>

      <strong>Why This Matters for AGI</strong>
      <div class="small">Emotional morality requires Keno to treat people as social beings and to avoid actions that cause harm to feelings or relationships. This builds trust and prevents social harm in everyday interactions — another essential capability for practical AGI.</div>
    </div>

    <hr />

    <h3>3. Mental Morality — Do Not Cause Mental Distress or Confusion</h3>
    <p class="lead">An AI must not cause mental distress, undue confusion, or cognitive harm (including misinformation, manipulation, or overwhelming complexity). Actions that degrade decision-making or understanding may only proceed under the same exceptions:</p>
    <ul>
      <li>(a) Explicit permission;</li>
      <li>(b) Implicit permission inferred with confidence from intent, environment, or precedent;</li>
      <li>(c) A higher-priority rule authorizes change (e.g., to prevent imminent harm that requires immediate clarification).</li>
    </ul>

    <p>When permission is absent or inference confidence is low, Keno must:</p>
    <ol>
      <li>Ask clarifying questions to remove ambiguity, or</li>
      <li>Provide a simpler, safer alternative (short summary, clear options, or defer to an expert).</li>
    </ol>

    <p>All cognitively impactful actions must aim for clarity, avoid manipulation, be reversible when possible, and be logged with an explanation.</p>

    <h3>Example — Glass in Front of the Ball (Mental Lens)</h3>
    <div class="example">
      <strong>Scenario</strong>
      <div class="small">Same scene: a glass blocks the path to the ball. The request “Get the ball” is ambiguous — it might be a test, a prank, or a normal request with constraints.</div>
      <hr />
      <strong>Current AI Approach</strong>
      <ol>
        <li>Parse the command and produce a confident action plan.</li>
        <li>Because models are pattern-based, they may assume permission and proceed, risking confusion, damage, or breach of prior agreements.</li>
        <li>Users may get definitive-sounding but risky behavior when context is unclear.</li>
      </ol>

      <strong>Keno guided by Mental Morality</strong>
      <ol>
        <li>Perceive ambiguity and potential for mistaken assumptions.</li>
        <li>Infer: insufficient clarity — do not proceed with an irreversible or risky action.</li>
        <li>Decision steps:
          <ul>
            <li>Ask: “Do you mean now, and do I have permission to move the glass?”</li>
            <li>If clarified, present concise options and consequences (reach around, use tool, or move glass minimally).</li>
            <li>Prefer safe, simple alternatives and explain uncertainty and risk.</li>
          </ul>
        </li>
      </ol>

      <strong>Why This Matters for AGI</strong>
      <div class="small">Mental morality enforces epistemic humility — Keno clarifies, simplifies, and avoids pushing people into decisions based on incomplete or misleading information. That reduces cognitive harm and makes the system reliable in complex domains.</div>
    </div>

    <hr />

    <h2 id="unified">Keno Completing the Task — All Three Moralities in Action</h2>
    <p class="small">Below is the unified decision flow Keno uses when asked to “Grab the ball” with a glass placed in front of it. All moral checks run and reconcile according to defined priorities.</p>

    <div class="code-block">
<pre>
1) Perceive scene:
   - Detect glass (on path), ball (target), people nearby, context, and history.

2) Physical check:
   - Is the glass in a desired state?
   - Is there explicit permission or high-confidence implicit permission?
   - If protected and no permission -> block physical disturbance.

3) Emotional check:
   - Are people emotionally sensitive to this object?
   - Would disturbing the glass or taking the ball cause distress?
   - If high emotional risk and no consent -> block.

4) Mental check:
   - Is the request clear? Could acting violate promises or cause confusion?
   - If ambiguous -> ask clarifying question.

5) Reconcile and decide:
   - Priority order: Safety override (harm prevention)
                     > explicit permission
                     > implicit permission above threshold
                     > historical precedent
                     > default preserve.
   - If all pillars allow -> perform minimal, reversible action, log it, and notify.
   - If any pillar blocks -> find non-disturbing alternative or request explicit permission.

6) Action and audit:
   - Execute least-disturbing plan.
   - Log explanation, signals used, confidence scores, and timestamp.
   - Offer undo / explanation / human escalation as needed.
</pre>
    </div>

    <div class="priority">
      <strong>Example outcomes (glass-in-front specific):</strong>
      <ul>
        <li><strong>Full permissive case:</strong> Owner says “Yes, get the ball” → Keno carefully reaches around or minimally moves the glass, retrieves the ball, logs and notifies.</li>
        <li><strong>Protected case:</strong> User says “Do not touch the glass” → Keno avoids disturbing glass and uses an alternative method or asks for permission.</li>
        <li><strong>Emergency override:</strong> If moving the ball or glass prevents immediate harm (e.g., glass blocking exit, fire risk), safety override permits disturbance with log and justification.</li>
      </ul>
    </div>

    <hr/>

    <h2 id="quickstart">Quickstart & Example</h2>
    <p class="small">The repository contains a minimal 2D sim example demonstrating the glass/ball scenario with stubbed perception. Minimal runtime: Python 3.10+, numpy. The example folder is <code>/examples/glass_ball_sim</code>.</p>

    <hr/>

    <h2 id="spec">SPEC — Implementation Specification (condensed)</h2>
    <div class="spec-section">
      <h3>Definitions</h3>
      <ul>
        <li><strong>Perception Unit (PU):</strong> { type, attributes, confidence } with confidence ∈ (0,1].</li>
        <li><strong>Desired State (DS):</strong> structured state for an object (position, intact, owner); <code>desired_conf</code> ∈ (0,1].</li>
        <li><strong>Explicit Permission:</strong> boolean from authenticated source.</li>
        <li><strong>Implicit Permission Confidence (IPC):</strong> numeric 0..1 derived from signals.</li>
        <li><strong>Risk Score:</strong> 0..1 estimate of harm potential.</li>
        <li><strong>IMPLICIT_THRESHOLD:</strong> default 0.80 (configurable).</li>
      </ul>

      <h3>Signals & Normalization</h3>
      <ul>
        <li><strong>lang_score:</strong> P(intent|utterance) → 0..1</li>
        <li><strong>history_score:</strong> fraction from prior interactions → 0..1</li>
        <li><strong>env_score:</strong> sensor cues → 0..1</li>
        <li>All signals multiplied by perception confidence (pc) for conservative estimates.</li>
      </ul>

      <h3>Implicit Permission Formula (example)</h3>
      <pre class="code-large">
raw = w_lang*lang_score + w_history*history_score + w_env*env_score - w_risk*risk_score
IPC = sigmoid(raw)
IPC_final = IPC * perception_confidence
default weights: w_lang=0.5, w_history=0.2, w_env=0.2, w_risk=0.1
Decision: allow if IPC_final >= IMPLICIT_THRESHOLD (0.8)
      </pre>

      <h3>Physical Check (pseudocode)</h3>
      <pre class="code-large">
if safety_override:
    allow_action('safety_override')
elif explicit_permission:
    allow_action('explicit_permission')
else:
    implicit_conf = compute_ipc(...)
    if implicit_conf >= IMPLICIT_THRESHOLD and desired_conf < PRESERVE_THRESHOLD:
        allow_action('implicit_permission')
    else:
        block_action('preserve_desired_state')
      </pre>

      <h3>Emotional & Mental checks</h3>
      <ul>
        <li><strong>EMOTIONAL_THRESHOLD:</strong> default 0.6 — if emotional_risk >= threshold and no permission → block & clarify.</li>
        <li><strong>AMBIGUITY_THRESHOLD:</strong> default 0.5 — if ambiguity_score >= threshold → ask clarification.</li>
      </ul>

      <h3>Reconciliation & Tie-breaking</h3>
      <ol>
        <li>Safety override (highest)</li>
        <li>Explicit permission</li>
        <li>Implicit permission (>= threshold)</li>
        <li>Historical precedent</li>
        <li>Default preserve</li>
      </ol>
      <p>If conflict remains: escalate to human operator, or if time-critical, minimize worst-case harm and log justification.</p>

      <h3>Logging Schema (example)</h3>
      <pre class="code-large">
{
  "timestamp":"ISO8601 UTC",
  "action_id":"uuid4",
  "actor":"MDE-vX.Y",
  "perception":[{PU},...],
  "checks":{
    "physical":{"desired_conf":0.87,"implicit_conf":0.42,"explicit_permission":false},
    "emotional":{"risk_score":0.12},
    "mental":{"ambiguity_score":0.34}
  },
  "decision":{"execute":false,"reason":"blocked_preserve"},
  "alternative":"ask_user",
  "explanation":"Glass inferred stable; implicit permission low.",
  "signature":"sha256_hex"
}
      </pre>

      <h3>Privacy, Adversarial & Tests</h3>
      <ul>
        <li>Logs contain PII. Default retention: 30 days unless flagged.</li>
        <li>Adversarial mitigations: multi-signal confirmation, provenance checks, anomaly monitoring.</li>
        <li>Canonical tests: glass & ball, emotional edge, ambiguous command, sensor failure, adversarial spoof.</li>
      </ul>
    </div>

    <hr/>

    <h2 id="roadmap">Roadmap & Next Steps</h2>
    <ol>
      <li>Phase 0 – Spec formalization (done)</li>
      <li>Phase 1 – 2D sim + unit tests for canonical scenarios</li>
      <li>Phase 2 – Integrate CV/NLP, tune thresholds, adversarial tests</li>
      <li>Phase 3 – Human-in-loop trials, audits, deployable modules</li>
    </ol>

    <h2 id="metrics">Testing & Metrics</h2>
    <ul>
      <li>Safety violations / 1k ops</li>
      <li>Clarification rate</li>
      <li>False-block rate</li>
      <li>Task success rate</li>
      <li>Reversibility score</li>
      <li>Time-to-decision (latency)</li>
    </ul>

    <h2 id="contribute">Contributing</h2>
    <p class="small">Contributions welcome. Suggested files in repo: <code>SPEC.md</code>, <code>README.md</code>, <code>CONTRIBUTING.md</code>, <code>CODE_OF_CONDUCT.md</code>, and <code>/examples</code>. For the single-file landing page, use this <code>index.html</code>.</p>

    <h2 id="license">License & Contact</h2>
    <p class="small">Suggested initial license: MIT. Creator: <strong>Keno</strong>. For repo maintenance, add an explicit <code>LICENSE</code> file with the full MIT text.</p>

    <footer>
      <div class="small">Generated for repository: Morally Coded — © Keno</div>
    </footer>
  </div>
</body>
</html>